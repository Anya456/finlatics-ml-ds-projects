# -*- coding: utf-8 -*-
"""Project1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1edQkKTdMgl5BDQRYVeki_4FlGK5kBMAO

Importing libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""Importing dataset"""

dataset = pd.read_csv('Facebook_Marketplace_data.csv')

print(dataset.head(10))

"""Dropping redundant columns"""

dataset.drop(columns=['Column1','Column2','Column3','Column4'],inplace=True)
print(dataset.columns)

"""Checking for null values"""

print(dataset.isnull().sum())

"""Relation between status_published and num_reactions"""

dataset['status_published'] = pd.to_datetime(dataset['status_published'])
hour = dataset['status_published'].dt.hour
day = dataset['status_published'].dt.day_name()
reactions = dataset['num_reactions'].values

"""Visualising the effect of hour of the day on num_reactions"""

dataset['hour'] = dataset['status_published'].dt.hour
avg_hour_reactions = dataset.groupby('hour')['num_reactions'].mean()
avg_hour_reactions.plot(color = 'salmon',marker='o')
plt.xlabel('Hour of the Day(0-23)')
plt.ylabel('Average Number of Reactions')
plt.title('Average No. of Reactions v/s Hour of the Day')
plt.show()

"""Visualising the effect of day of the week on reactions"""

dataset['day'] = dataset['status_published'].dt.day_name()
avg_day_reactions = dataset.groupby('day')['num_reactions'].mean()
day_order = ['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']
avg_day_reactions = avg_day_reactions.reindex(day_order)
avg_day_reactions.plot(marker = 'o', color = '#063970')
plt.xlabel('Days of the Week')
plt.ylabel('Average Number of Reactions')
plt.title('Average No. of Reactions v/s Day of the Week')
plt.show()

"""Checking correlation between num_reactions, num_comments, and num_shares"""

import seaborn as sns
selected_dataset = dataset[['num_reactions','num_comments','num_shares']]
corr_matrix = selected_dataset.corr()
plt.figure(figsize = (6,4))
sns.heatmap(corr_matrix, annot = True, cmap = 'crest', fmt = '0.2f')
plt.title('Correlation Matrix')
plt.show()

"""K Means Clustering"""

cols = ['status_type', 'num_reactions', 'num_comments', 'num_shares',
    'num_likes', 'num_loves', 'num_wows', 'num_hahas', 'num_sads', 'num_angrys']
x = dataset[cols].copy()

"""Encoding categorical variables"""

x = pd.get_dummies(x, columns = ['status_type'], dtype= int)
print(x.head(8))

"""Finding optimal value of k using elbow method"""

wcss = []

from sklearn.cluster import KMeans
for i in range(1,11):
  kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 1)
  kmeans.fit(x)
  wcss.append(kmeans.inertia_)

plt.plot(range(1,11), wcss, marker = 'o')
plt.title('Elbow Method')
plt.xlabel('No. of Clusters')
plt.ylabel('WCSS')
plt.show()

"""Training K Means model on the dataset"""

kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 1)
kmeans.fit(x)

"""Count of different types of posts"""

print(dataset['status_type'].value_counts())

"""Average value of num_reaction, num_comments, num_shares for each post type"""

averages = dataset.groupby('status_type')[['num_reactions','num_comments','num_shares']].mean()
print(averages)